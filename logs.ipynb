{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Logs\n",
    "All results displayed with the following specification:\n",
    "- Model = sentence-transformers/LaBSE\n",
    "- Keep F1 Score Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nusax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Command ```python bitext.py --src_lang eng --dataset nusax --seed 42 --cuda --model_checkpoint sentence-transformers/LaBSE ```\n",
    "- Note that src language is 'eng' instead of 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                1         5        10\n",
      "ace      0.708867  0.808400  0.842333\n",
      "ban      0.828267  0.919000  0.926333\n",
      "bbc      0.574229  0.695465  0.733300\n",
      "bjn      0.893000  0.952333  0.963000\n",
      "bug      0.440918  0.558769  0.625303\n",
      "ind      0.976000  0.986667  0.986667\n",
      "jav      0.976000  0.981333  0.984000\n",
      "mad      0.593802  0.723538  0.801700\n",
      "min      0.897133  0.950333  0.958333\n",
      "nij      0.711605  0.793238  0.843400\n",
      "sun      0.968333  0.979000  0.979000\n",
      "Average  0.778923  0.849825  0.876670\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path to the directory and initialize variables\n",
    "directory_path = \"outputs/save_bitext/nusax/sentence-transformers/LaBSE/seed_42\" \n",
    "language_pairs = ['ace', 'ban', 'bbc', 'bjn', 'bug', 'ind', 'jav', 'mad', 'min', 'nij', 'sun']\n",
    "k_values = ['1', '5', '10']\n",
    "\n",
    "# Initialize an empty dictionary to store F1 scores for k=1,5,10 for each language pair\n",
    "f1_scores = {k: [] for k in k_values}\n",
    "\n",
    "# Iterate over the files in the directory and extract F1 scores\n",
    "for lang in language_pairs:\n",
    "    for k in k_values:\n",
    "        file_name = f\"eval_eng_{lang}_{k}.json\"\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        # Open and read the JSON file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            f1_scores[k].append(data[\"f1\"])\n",
    "\n",
    "# Convert the dictionary to a DataFrame and calculate the average F1 scores\n",
    "df = pd.DataFrame(f1_scores)\n",
    "df.index = language_pairs\n",
    "df.loc['Average'] = df.mean()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUCC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MINERS's bucc dataset has inverted source language, therefore 3 commands are required to run:\n",
    "    - ```python bitext.py --src_lang de --dataset bucc --seed 42 --cuda --model_checkpoint sentence-transformers/LaBSE ```\n",
    "    - ```python bitext.py --src_lang fr --dataset bucc --seed 42 --cuda --model_checkpoint sentence-transformers/LaBSE ```\n",
    "    - ```python bitext.py --src_lang zh --dataset bucc --seed 42 --cuda --model_checkpoint sentence-transformers/LaBSE ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                1         5        10\n",
      "de       0.994294  0.997495  0.998330\n",
      "fr       0.989489  0.995304  0.995598\n",
      "zh       0.992277  0.994383  0.994383\n",
      "Average  0.992020  0.995727  0.996103\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"outputs/save_bitext/bucc/sentence-transformers/LaBSE/seed_42\"  \n",
    "language_pairs = ['de','fr','zh']\n",
    "k_values = ['1', '5', '10']\n",
    "\n",
    "# Initialize an empty dictionary to store F1 scores for k=1,5,10 for each language pair\n",
    "f1_scores = {k: [] for k in k_values}\n",
    "\n",
    "# Iterate over the files in the directory and extract F1 scores\n",
    "for lang in language_pairs:\n",
    "    for k in k_values:\n",
    "        file_name = f\"eval_{lang}_en_{k}.json\"\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        # Open and read the JSON file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            f1_scores[k].append(data[\"f1\"])\n",
    "\n",
    "# Convert the dictionary to a DataFrame and calculate the average F1 scores\n",
    "df = pd.DataFrame(f1_scores)\n",
    "df.index = language_pairs\n",
    "df.loc['Average'] = df.mean()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NollySenti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Command ```python bitext.py --src_lang en --dataset nollysenti --seed 42 --cuda --model_checkpoint sentence-transformers/LaBSE```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                1         5        10\n",
      "en400    0.227169  0.229447  0.232640\n",
      "ha       0.227474  0.229752  0.229752\n",
      "ig       0.208863  0.228777  0.232717\n",
      "pcm      0.211215  0.218597  0.219969\n",
      "yo400    0.146419  0.193499  0.204091\n",
      "Average  0.204228  0.220015  0.223834\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"outputs/save_bitext/nollysenti/sentence-transformers/LaBSE/seed_42\"\n",
    "language_pairs = ['en400', 'ha', 'ig', 'pcm', 'yo400']\n",
    "k_values = ['1', '5', '10']\n",
    "\n",
    "# Initialize an empty dictionary to store F1 scores for k=1,5,10 for each language pair\n",
    "f1_scores = {k: [] for k in k_values}\n",
    "\n",
    "# Iterate over the files in the directory and extract F1 scores\n",
    "for lang in language_pairs:\n",
    "    for k in k_values:\n",
    "        file_name = f\"eval_en_{lang}_{k}.json\"\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        # Open and read the JSON file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            f1_scores[k].append(data[\"f1\"])\n",
    "\n",
    "# Convert the dictionary to a DataFrame and calculate the average F1 scores\n",
    "df = pd.DataFrame(f1_scores)\n",
    "df.index = language_pairs\n",
    "df.loc['Average'] = df.mean()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                1         5        10\n",
      "en400    0.283684  0.286529  0.291980\n",
      "ha       0.284254  0.287099  0.287099\n",
      "ig       0.261704  0.287028  0.291948\n",
      "pcm      0.265010  0.274640  0.277166\n",
      "yo400    0.185283  0.244512  0.258241\n",
      "Average  0.255987  0.275962  0.281287\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "directory_path = \"outputs/save_bitext/nollysenti/sentence-transformers/LaBSE/seed_42\"\n",
    "language_pairs = ['en400', 'ha', 'ig', 'pcm', 'yo400']\n",
    "k_values = ['1', '5', '10']\n",
    "\n",
    "# Initialize an empty dictionary to store F1 scores for k=1,5,10 for each language pair\n",
    "f1_scores = {k: [] for k in k_values}\n",
    "\n",
    "# Iterate over the files in the directory and extract F1 scores\n",
    "for lang in language_pairs:\n",
    "    for k in k_values:\n",
    "        file_name = f\"eval_en_{lang}_{k}.json\"\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        # Open and read the JSON file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            f1_scores[k].append(data[\"f1\"])\n",
    "\n",
    "# Convert the dictionary to a DataFrame and calculate the average F1 scores\n",
    "df = pd.DataFrame(f1_scores)\n",
    "df.index = language_pairs\n",
    "df.loc['Average'] = df.mean()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Added Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Subtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Command ```python bitext.py --src_lang en --dataset opensub --seed 42 --cuda --model_checkpoint sentence-transformers/LaBSE ```\n",
    "- Credit: [loicmagne-HuggingFace](https://huggingface.co/datasets/loicmagne/open-subtitles-bitext-mining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                1         5        10\n",
      "af       0.787919  0.863133  0.882233\n",
      "Average  0.787919  0.863133  0.882233\n"
     ]
    }
   ],
   "source": [
    "directory_path = \"outputs/save_bitext/opensub/sentence-transformers/LaBSE/seed_42\"\n",
    "language_pairs = ['af']\n",
    "k_values = ['1', '5', '10']\n",
    "\n",
    "# Initialize an empty dictionary to store F1 scores for k=1,5,10 for each language pair\n",
    "f1_scores = {k: [] for k in k_values}\n",
    "\n",
    "# Iterate over the files in the directory and extract F1 scores\n",
    "for lang in language_pairs:\n",
    "    for k in k_values:\n",
    "        file_name = f\"eval_{lang}_en_{k}.json\"\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        # Open and read the JSON file\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            f1_scores[k].append(data[\"f1\"])\n",
    "\n",
    "# Convert the dictionary to a DataFrame and calculate the average F1 scores\n",
    "df = pd.DataFrame(f1_scores)\n",
    "df.index = language_pairs\n",
    "df.loc['Average'] = df.mean()\n",
    "\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
